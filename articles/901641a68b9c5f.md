---
title: "主成分分析の理論"
emoji: "🦔"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["PCA", "主成分分析", "PrincipleComponentAnalysis"]
published: True
---
# 主成分分析とは
主成分分析とは、**多次元のデータを少量の新しい変数（主成分）に変換して、データの構造をわかりやすくする統計手法**です。  
この資料は、多くの開発者が利用しているこの「主成分分析」の理論的な背景をしっかり説明することを目的として書きました。

もう少し具体的に説明すると、主成分分析とは、データの分散が大きい軸を見つけだすことで、多次元のデータを低次元に圧縮し、ノイズや冗長な情報を減らす統計的な分析手法です。  

:::details 例えば  
生徒全員が同じような点数を取った数学のテストと、
生徒全員ばらばらの点数を取った国語のテストがあるとします。

この場合、国語のテストのほうが「優秀な学生を見極めるための材料」になるでしょう。  
なぜなら、同じような点数をとったテストでは優秀な学生も普通の学生も大して点数が変わらないからです。

そして、この「ばらばら」の度合いが大きい（分散が大きい）ほど情報量が多い、という思想のもと考えられた次元圧縮方法が、この主成分分析です。

:::

## 今回考えること
例えば、「体重」「身長」を表すデータがあったとして、これをひとつの軸で表現するとしたら、どうするが良いでしょうか？  

:::details 具体的には
もし以下のように「体重」「身長」を表すデータがあったとして、これをひとつの軸で表現するとしたら、どうするが良いでしょうか？

![](https://storage.googleapis.com/zenn-user-upload/51115872d964-20250807.png)

おそらく、ほとんどの人はこんな風に軸をとるでしょう。  
実際に主成分分析を行うと、「第一主成分」としてこのような軸が求まります。
![](https://storage.googleapis.com/zenn-user-upload/bde6ea1ede6f-20250807.png)


:::

## 計算の準備
まずはk個のデータ点を用意しましょう。今回は、それぞれのデータが「身長」と「体重」を持っているとします。

$$
\bm{\mathrm{data}_1} = (176, 68)^{\mathrm{T}}\\
\bm{\mathrm{data}_2} = (165, 60)^{\mathrm{T}}\\
\vdots \\
\bm{\mathrm{data}_k} = (163, 63)^{\mathrm{T}}
$$

ただ、cmとkgという別々の単位を同等に扱うのはおかしいので、まずはデータを標準化して、新しいデータを $\bm{x_i}$ と書き直しておきます。

$$
\bm{x_1} = (0.16, 0.26)^{\mathrm{T}}\\
\bm{x_2} = (-0.06, -0.22)^{\mathrm{T}}\\
\vdots \\
\bm{x_k} = (-0.10, -0.04)^{\mathrm{T}}
$$

:::details 標準化  
標準化とはデータを、平均が $0$ 、分散が $1$ になるように均す作業のことです。  
これによって、違う単位のデータを同等に扱うことができるようになります。

具体的には、各データから平均を引いて、分散で割ることを標準化と言います。

$$
\frac{x_i - \mathrm{average}(\bm{x})}{\mathrm{variance}(\bm{x})}
$$

:::

## 主成分の計算
標準化したデータ $\bm{x_i}$ に対して主成分分析をしていきましょう。まずは、軸の向きを表す単位ベクトルを定義します。

$$
\bm{e} = (e_1, e_2)^{\mathrm{T}} \in \mathbb{R}^2, \quad \text{ただし} \quad e_1^2 + e_2^2 = 1
$$

では、データをを最もばらばらに表現するベクトル $\mathbf{e}$ とはどんな風に書けるでしょうか。  
それは、内積を使って以下のように書くことができます。

$$
\bm{e} = \argmax_{\bm{e}} \sum_{i=1}^{k} (\bm{x_i} ^{\mathrm{T}} \bm{e})^2
$$

ここで $\argmax$ の内部は定数倍しても値が変わらないので、後の計算のために $\frac{1}{k}$ を掛けておきます。

$$
\bm{e} = \argmax_{\bm{e}} \frac{1}{k} \sum_{i=1}^{k} (\bm{x_i} ^{\mathrm{T}} \bm{e})^2
$$

以上を準備として、改めてこの問題を整理すると、以下のようになります。

:::message  
考えたい問題

$$
e_1^2 + e_2^2 = \bm{e}^{\mathrm{T}}\bm{e} = 1
$$

という条件のもとで、

$$
\frac{1}{k} \sum_{i=1}^{k} (\bm{x_i}^{\mathrm{T}} \bm{e})^2 = \frac{1}{k} \sum_{i=1}^{k} \bm{e}^{\mathrm{T}} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e} = \frac{1}{k} \bm{e}^{\mathrm{T}} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e}
$$

が最大となるような $\bm{e}$ を求める。

:::

:::details ラグランジュ未定乗数法
ある条件 $g(x, y)=0$ のもとで、ある関数 $f(x, y)$ が最大となるような $x, y$ を求める、という問題は、まさに**ラグランジュ未定乗数法**で解けることが知られています。  
これは、 $g(x, y)=0$ のもとで $f(x, y)$ が最大となるとき、必ず $f(x,y)$ の等高線における共偏微分と $g(x,y)$ における共偏微分の向きが一致すること、つまり、任意の $\lambda$ を用いて

$$
\nabla f = \lambda \nabla g
$$

を利用した、非常にエレガントな解き方です。  
[参考(wikipedia)](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E3%81%AE%E6%9C%AA%E5%AE%9A%E4%B9%97%E6%95%B0%E6%B3%95#:~:text=%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E3%81%AE%E6%9C%AA%E5%AE%9A%E4%B9%97%E6%95%B0%E6%B3%95%EF%BC%88%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E3%81%AE%E3%81%BF%E3%81%A6%E3%81%84%E3%81%98%E3%82%87%E3%81%86%E3%81%99%E3%81%86,%E7%9A%84%E3%81%AA%E6%96%B9%E6%B3%95%E3%81%A7%E3%81%82%E3%82%8B%E3%80%82)
:::

この問題では、ラグランジュ未定乗数法の $g, f$ が以下のように対応しています。

$$
\begin{aligned}
g(e_1, e_2) &= \bm{e}^{\mathrm{T}}\bm{e} - 1 = 0\\
f(e_1, e_2) &= \frac{1}{k} \bm{e}^{\mathrm{T}} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e}
\end{aligned}
$$

したがって、ラグランジュ未定乗数法を用いると問題は以下のように書き直すことができます。

$$
\nabla \left( \frac{1}{k} \bm{e}^{\mathrm{T}} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e} \right) = \lambda \nabla \left( \bm{e}^{\mathrm{T}}\bm{e} - 1 \right)
$$

これは、計算すると以下のように書き直せます。

$$
\frac{2}{k} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e} = 2 \lambda \bm{e}\\
\therefore \frac{1}{k} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}} \bm{e} = \lambda \bm{e}
$$

ここまで来たらもうわかると思いますが、最終的にこの問題は以下のように帰結しました。

:::message  
最終的に解きたい問題

$$
\bm{C} = \frac{1}{k} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}}
$$
という行列に対する

$$
\bm{C} \bm{e} = \lambda \bm{e}
$$
という固有値問題

:::

:::details 分散共分散行列  
ここで、$\frac{1}{k}$ をかけておいた理由を説明しておきます。  
標準化したデータにおいて、

$$
\bm{C} = \frac{1}{k} \sum_{i=1}^{k} \bm{x_i}\bm{x_i}^{\mathrm{T}}
$$

このような行列のことを、分散共分散行列と言い、これは元のデータから簡単に計算することができます。  
つまり、分散共分散行列を計算し、固有値問題を解くだけで主成分は計算できるのです。

:::

$\lambda$ と、それに対応するベクトル $\bm{e}$ は複数与えられますが、$\lambda$ が大きいものから順に「第n負荷量ベクトル」と呼びます。  
また、$\lambda$ 自身も「寄与度」、「累積寄与度」を計算する上で非常に重要な役割を果たします。

## 寄与度

計算した $\lambda$ を大きいのもから順に $\lambda_1 , \lambda_2, ... \lambda_i$ と呼ぶことにすると、第 $j$ 主成分の寄与度を

$$
\frac{\lambda_j}{\sum^{i}_{k=1} \lambda_k}
$$

と定義します。

## 累積寄与度

計算した $\lambda$ を大きいのもから順に $\lambda_1 , \lambda_2, ... \lambda_i$ と呼ぶことにすると、第 $j$ 主成分までの累積寄与度を

$$
\frac{\sum^{i}_{l=1} \lambda_l}{\sum^{i}_{k=1} \lambda_k}
$$

と定義します。